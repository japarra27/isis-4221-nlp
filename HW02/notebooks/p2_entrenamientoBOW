# Databricks notebook source
# MAGIC %md
# MAGIC # NLP - HW2: Parte2A: Entrenamiento BOW

# COMMAND ----------

# MAGIC %md
# MAGIC Con el objetivo de aplicar los conocimientos presentados en clase y a su vez generar los modelos solicitados, en este punto se hará uso de la herramienta Databricks y Pyspark con el objetivo de leer los archivos, generar la construcción del dataset y hacer el entrenamiento respectivo de los modelos.
# MAGIC 
# MAGIC Para la elaboración de la actividad se sigue una serie de pasos:
# MAGIC 
# MAGIC * Se crea un cluster de spark 3.1 en Databricks, con mínimo 1 driver, 1 nodo y autoescalable a máximo 20.
# MAGIC * Cada nodo es una instancia m4.large de AWS con 2 core y 8gb ram, el driver tiene la misma configuración.
# MAGIC * Los archivos se almacenan en un bucket de s3, se descomprime y se hace la lectura para la construcción del dataset.
# MAGIC * Se hace uso de spark para paralelizar los trabajos y hacerlos más eficiente a la hora de entrenar los modelos.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Punto No. 2: Naive Bayes (NB) & Logistic Regression (LR)
# MAGIC 
# MAGIC ### For the 20N dataset compare two classifiers NB and LR to identify the 20 different newsgroups.

# COMMAND ----------

# importar librerias

import pyspark.sql.functions as F
from pyspark.sql.types import *

# Librerias para procesar datos
from pyspark.ml import Pipeline
from pyspark.ml.feature import CountVectorizer, StringIndexer,  HashingTF, IDF

# librerias sparknlp
import sparknlp
from sparknlp.base import *
from sparknlp.common import *
from sparknlp.annotator import *

# ml libraries
from pyspark.ml.classification import NaiveBayes, LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# COMMAND ----------

# Importar dataset procesado para la ejecución de los modelos
sdf = spark.read.format('parquet').load('/mnt/databricks-mine/HW02/news20processed')

# COMMAND ----------

# Creación del pipeline para hacer el modelo
indexer = StringIndexer(inputCol="fileName", outputCol="labelIndex")
bow = CountVectorizer(inputCol="tokens", outputCol="features_bow")

# Definición del pipeline
pipeline = Pipeline(stages=[indexer, bow])

# fit y transform del pipeline
pipeData = pipeline.fit(sdf).transform(sdf)

# COMMAND ----------

pipeData.select("fileName","labelIndex").groupBy('fileName', 'labelIndex').count().orderBy('labelIndex').show(25)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Divide the dataset into training (60%), development (10%) and test (30%)

# COMMAND ----------

model = pipeData.select('labelIndex', 'features_bow')
(trainData, testData, devData) = model.randomSplit([0.6, 0.3, 0.1], seed=321)

# COMMAND ----------

# MAGIC %md 
# MAGIC ##### Train NB and LR using the following representations:

# COMMAND ----------

# MAGIC %md
# MAGIC ###### BOW

# COMMAND ----------

# MAGIC %md
# MAGIC Train BOW models

# COMMAND ----------

# NaiveBayes
nbBow = NaiveBayes(modelType="multinomial",labelCol="labelIndex", featuresCol="features_bow")
nbModelBow = nbBow.fit(trainData).transform(testData)

# COMMAND ----------

# LogisticRegression
lrBow = LogisticRegression(labelCol="labelIndex", featuresCol="features_bow")
lrModelBow = lrBow.fit(trainData).transform(testData)

# COMMAND ----------

# MAGIC %md
# MAGIC Test BOW models

# COMMAND ----------

nbModelBow.select("prediction", "labelIndex", "features_bow").show(5)

# COMMAND ----------

lrModelBow.select("prediction", "labelIndex", "features_bow").show(5)

# COMMAND ----------

# Rvaluación NaiveBayes
evaluator = MulticlassClassificationEvaluator(labelCol="labelIndex", predictionCol="prediction", metricName="accuracy")
nb_accuracy = evaluator.evaluate(nbModelBow)
print("Accuracy of NaiveBayes is = %g"% (nb_accuracy))
print("Test Error of NaiveBayes = %g " % (1.0 - nb_accuracy))