{"cells":[{"cell_type":"markdown","source":["# NLP - HW2 - Parte2A: Entrenamiento TfIdf"],"metadata":{}},{"cell_type":"markdown","source":["Con el objetivo de aplicar los conocimientos presentados en clase y a su vez generar los modelos solicitados, en este punto se hará uso de la herramienta Databricks y Pyspark con el objetivo de leer los archivos, generar la construcción del dataset y hacer el entrenamiento respectivo de los modelos.\n\nPara la elaboración de la actividad se sigue una serie de pasos:\n\n* Se crea un cluster de spark 3.1 en Databricks, con mínimo 1 driver, 1 nodo y autoescalable a máximo 20.\n* Cada nodo es una instancia m4.large de AWS con 2 core y 8gb ram, el driver tiene la misma configuración.\n* Los archivos se almacenan en un bucket de s3, se descomprime y se hace la lectura para la construcción del dataset.\n* Se hace uso de spark para paralelizar los trabajos y hacerlos más eficiente a la hora de entrenar los modelos."],"metadata":{}},{"cell_type":"markdown","source":["## Punto No. 2: Naive Bayes (NB) & Logistic Regression (LR)\n\n### For the 20N dataset compare two classifiers NB and LR to identify the 20 different newsgroups."],"metadata":{}},{"cell_type":"code","source":["# importar librerias\n\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import *\n\n# Librerias para procesar datos\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import CountVectorizer, StringIndexer,  HashingTF, IDF\n\n# librerias sparknlp\nimport sparknlp\nfrom sparknlp.base import *\nfrom sparknlp.common import *\nfrom sparknlp.annotator import *\n\n# ml libraries\nfrom pyspark.ml.classification import NaiveBayes, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Importar dataset procesado para la ejecución de los modelos\nsdf = spark.read.format('parquet').load('/mnt/databricks-mine/HW02/news20processed')"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Creación del pipeline para hacer el modelo\nindexer = StringIndexer(inputCol=\"fileName\", outputCol=\"labelIndex\")\nhasher = HashingTF(inputCol='tokens', outputCol=\"hash\")\nidf = IDF(inputCol='hash', outputCol=\"features_tfidf\")\n\n# Definición del pipeline\npipeline = Pipeline(stages=[indexer, hasher, idf])\n\n# fit y transform del pipeline\npipeData = pipeline.fit(sdf).transform(sdf)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["pipeData.select(\"fileName\",\"labelIndex\").groupBy('fileName', 'labelIndex').count().orderBy('labelIndex').show(25)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------+-----+\n            fileName|labelIndex|count|\n+--------------------+----------+-----+\n    rec.sport.hockey|       0.0|  999|\nsoc.religion.chri...|       1.0|  997|\n     rec.motorcycles|       2.0|  994|\n  rec.sport.baseball|       3.0|  994|\n           sci.crypt|       4.0|  991|\n           rec.autos|       5.0|  990|\n             sci.med|       6.0|  990|\n           sci.space|       7.0|  987|\ncomp.os.ms-window...|       8.0|  985|\ncomp.sys.ibm.pc.h...|       9.0|  982|\n     sci.electronics|      10.0|  981|\n      comp.windows.x|      11.0|  980|\n       comp.graphics|      12.0|  973|\n        misc.forsale|      13.0|  972|\ncomp.sys.mac.hard...|      14.0|  961|\ntalk.politics.mid...|      15.0|  940|\n  talk.politics.guns|      16.0|  910|\n         alt.atheism|      17.0|  799|\n  talk.politics.misc|      18.0|  775|\n  talk.religion.misc|      19.0|  628|\n+--------------------+----------+-----+\n\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["##### Divide the dataset into training (60%), development (10%) and test (30%)"],"metadata":{}},{"cell_type":"code","source":["model = pipeData.select('labelIndex', 'features_tfidf')\n(trainData, testData, devData) = model.randomSplit([0.6, 0.3, 0.1], seed=321)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["##### Train NB and LR using the following representations:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["###### Personalized representation. You as a designer must define the select set of characteristics. Explain your feature selection strategy in detail."],"metadata":{}},{"cell_type":"markdown","source":["Train tfidf selection strategy"],"metadata":{}},{"cell_type":"code","source":["# NaiveBayes\nnbTf = NaiveBayes(modelType=\"multinomial\",labelCol=\"labelIndex\", featuresCol=\"features_tfidf\")\nnbModelTf = nbTf.fit(trainData).transform(testData)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# LogisticRegression\nlrTf = LogisticRegression(labelCol=\"labelIndex\", featuresCol=\"features_tfidf\")\nlrModelTf = lrTf.fit(trainData).transform(testData)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Test tfidf selection models"],"metadata":{}},{"cell_type":"code","source":["nbModelTf.select(\"prediction\", \"labelIndex\", \"features_tfidf\").show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+--------------------+\nprediction|labelIndex|      features_tfidf|\n+----------+----------+--------------------+\n      15.0|      15.0|(262144,[1,432,53...|\n      15.0|      15.0|(262144,[56,619,1...|\n      15.0|      15.0|(262144,[95,535,8...|\n      15.0|      15.0|(262144,[154,1971...|\n      15.0|      15.0|(262144,[181,535,...|\n+----------+----------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["lrModelTf.select(\"prediction\", \"labelIndex\", \"features_tfidf\").show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+--------------------+\nprediction|labelIndex|      features_tfidf|\n+----------+----------+--------------------+\n      15.0|      15.0|(262144,[1,432,53...|\n      15.0|      15.0|(262144,[56,619,1...|\n      15.0|      15.0|(262144,[95,535,8...|\n      18.0|      15.0|(262144,[154,1971...|\n      15.0|      15.0|(262144,[181,535,...|\n+----------+----------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["# Evaluación NaiveBayes\nevaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\nnb_accuracy = evaluator.evaluate(nbModelTf)\nprint(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))\nprint(\"Test Error of NaiveBayes = %g \" % (1.0 - nb_accuracy))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of NaiveBayes is = 0.933145\nTest Error of NaiveBayes = 0.0668553 \n</div>"]}}],"execution_count":19}],"metadata":{"name":"HW02 - NLP - Act2 tfidf","notebookId":541},"nbformat":4,"nbformat_minor":0}